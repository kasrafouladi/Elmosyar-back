import os
import re
import json
from datetime import datetime, timedelta
from pathlib import Path

from django.conf import settings
from django.http import HttpResponse, JsonResponse
from rest_framework.decorators import api_view, permission_classes
from rest_framework.permissions import IsAuthenticated
from rest_framework.response import Response
from rest_framework import status
from django.core.paginator import Paginator
from django.db.models import Q

from .permissions import IsSuperUser
from .log_config import logger, log_info, log_error

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“Š Log Management Endpoints (Only for Superusers)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@api_view(['GET'])
@permission_classes([IsAuthenticated, IsSuperUser])
def list_log_files(request):
    """
    Ù„ÛŒØ³Øª ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù„Ø§Ú¯ Ù…ÙˆØ¬ÙˆØ¯
    ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ø³ÙˆÙ¾Ø± ÛŒÙˆØ²Ø±Ù‡Ø§
    """
    try:
        log_dir = getattr(settings, 'LOG_DIR', os.path.join(settings.BASE_DIR, 'logs'))
        
        if not os.path.exists(log_dir):
            return Response({
                'success': False,
                'message': 'Ù¾ÙˆØ´Ù‡ Ù„Ø§Ú¯â€ŒÙ‡Ø§ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯'
            }, status=status.HTTP_404_NOT_FOUND)
        
        log_files = []
        for file_name in os.listdir(log_dir):
            if file_name.endswith('.log'):
                file_path = os.path.join(log_dir, file_name)
                stat = os.stat(file_path)
                
                # Ø®ÙˆØ§Ù†Ø¯Ù† Ú†Ù†Ø¯ Ø®Ø· Ø§ÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡
                preview_lines = []
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        for _ in range(5):
                            line = f.readline()
                            if line:
                                preview_lines.append(line.strip())
                except:
                    preview_lines = ["Ù‚Ø§Ø¨Ù„ Ø®ÙˆØ§Ù†Ø¯Ù† Ù†ÛŒØ³Øª"]
                
                log_files.append({
                    'name': file_name,
                    'size': stat.st_size,
                    'size_human': _human_readable_size(stat.st_size),
                    'modified': datetime.fromtimestamp(stat.st_mtime),
                    'preview': preview_lines[:3]  # ÙÙ‚Ø· Û³ Ø®Ø· Ø§ÙˆÙ„
                })
        
        # Ù„Ø§Ú¯ Ú©Ø±Ø¯Ù† Ø¯Ø³ØªØ±Ø³ÛŒ
        logger.audit_trail(
            f"Superuser '{request.user.username}' viewed log files list",
            request
        )
        
        return Response({
            'success': True,
            'log_dir': log_dir,
            'files': sorted(log_files, key=lambda x: x['modified'], reverse=True),
            'total_files': len(log_files)
        })
        
    except Exception as e:
        log_error(f"Failed to list log files: {str(e)}", request)
        return Response({
            'success': False,
            'message': 'Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù„Ø§Ú¯'
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['GET'])
@permission_classes([IsAuthenticated, IsSuperUser])
def read_logs(request):
    """
    Ø®ÙˆØ§Ù†Ø¯Ù† Ù„Ø§Ú¯â€ŒÙ‡Ø§ Ø¨Ø§ ÙÛŒÙ„ØªØ± Ùˆ ØµÙØ­Ù‡â€ŒØ¨Ù†Ø¯ÛŒ
    ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ø³ÙˆÙ¾Ø± ÛŒÙˆØ²Ø±Ù‡Ø§
    """
    try:
        # Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ ÙÛŒÙ„ØªØ±
        log_file = request.GET.get('file', 'application.log')
        level = request.GET.get('level')  # DEBUG, INFO, WARNING, ERROR, CRITICAL
        user_filter = request.GET.get('user')
        ip_filter = request.GET.get('ip')
        search_text = request.GET.get('search')
        date_from = request.GET.get('date_from')
        date_to = request.GET.get('date_to')
        page = int(request.GET.get('page', 1))
        per_page = min(int(request.GET.get('per_page', 100)), 1000)
        
        # Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ù„Ø§Ú¯
        log_dir = getattr(settings, 'LOG_DIR', os.path.join(settings.BASE_DIR, 'logs'))
        file_path = os.path.join(log_dir, log_file)
        
        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ ÙØ§ÛŒÙ„
        if not os.path.exists(file_path):
            return Response({
                'success': False,
                'message': f'ÙØ§ÛŒÙ„ Ù„Ø§Ú¯ "{log_file}" ÛŒØ§ÙØª Ù†Ø´Ø¯'
            }, status=status.HTTP_404_NOT_FOUND)
        
        # Ø®ÙˆØ§Ù†Ø¯Ù† Ùˆ ÙÛŒÙ„ØªØ± Ù„Ø§Ú¯â€ŒÙ‡Ø§
        logs = []
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                
                # Ù¾Ø§Ø±Ø³ Ú©Ø±Ø¯Ù† Ø®Ø· Ù„Ø§Ú¯
                log_entry = _parse_log_line(line)
                
                # Ø§Ø¹Ù…Ø§Ù„ ÙÛŒÙ„ØªØ±Ù‡Ø§
                include = True
                
                if level and log_entry.get('level') != level.upper():
                    include = False
                
                if user_filter and user_filter not in log_entry.get('user', ''):
                    include = False
                
                if ip_filter and ip_filter not in log_entry.get('ip', ''):
                    include = False
                
                if search_text and search_text.lower() not in line.lower():
                    include = False
                
                if date_from and log_entry.get('timestamp'):
                    try:
                        log_date = datetime.strptime(log_entry['timestamp'], '%Y-%m-%d %H:%M:%S')
                        filter_date = datetime.strptime(date_from, '%Y-%m-%d')
                        if log_date.date() < filter_date.date():
                            include = False
                    except:
                        pass
                
                if date_to and log_entry.get('timestamp'):
                    try:
                        log_date = datetime.strptime(log_entry['timestamp'], '%Y-%m-%d %H:%M:%S')
                        filter_date = datetime.strptime(date_to, '%Y-%m-%d')
                        if log_date.date() > filter_date.date():
                            include = False
                    except:
                        pass
                
                if include:
                    logs.append({
                        'raw': line,
                        'parsed': log_entry,
                        'highlight': _highlight_log_line(line)
                    })
        
        # Ù…Ø±ØªØ¨ Ø³Ø§Ø²ÛŒ (Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† Ø§ÙˆÙ„)
        logs.reverse()
        
        # ØµÙØ­Ù‡â€ŒØ¨Ù†Ø¯ÛŒ
        paginator = Paginator(logs, per_page)
        try:
            page_obj = paginator.page(page)
        except:
            page_obj = paginator.page(1)
        
        # Ø¢Ù…Ø§Ø±
        level_stats = {}
        user_stats = {}
        for log in logs[:1000]:  # ÙÙ‚Ø· Û±Û°Û°Û° Ø®Ø· Ø§ÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ø¢Ù…Ø§Ø±
            entry = log['parsed']
            level = entry.get('level', 'UNKNOWN')
            user = entry.get('user', 'anonymous')
            
            level_stats[level] = level_stats.get(level, 0) + 1
            user_stats[user] = user_stats.get(user, 0) + 1
        
        # Ù„Ø§Ú¯ Ú©Ø±Ø¯Ù† Ø¯Ø³ØªØ±Ø³ÛŒ
        logger.audit_trail(
            f"Superuser '{request.user.username}' read logs from '{log_file}'",
            request,
            {'filters': request.GET.dict()}
        )
        
        return Response({
            'success': True,
            'file': log_file,
            'logs': [log['highlight'] for log in page_obj.object_list],
            'pagination': {
                'page': page,
                'per_page': per_page,
                'total_pages': paginator.num_pages,
                'total_count': paginator.count,
                'has_next': page_obj.has_next(),
                'has_previous': page_obj.has_previous(),
            },
            'statistics': {
                'levels': level_stats,
                'top_users': dict(sorted(user_stats.items(), key=lambda x: x[1], reverse=True)[:10]),
                'file_size': _human_readable_size(os.path.getsize(file_path))
            }
        })
        
    except Exception as e:
        log_error(f"Failed to read logs: {str(e)}", request)
        return Response({
            'success': False,
            'message': f'Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† Ù„Ø§Ú¯â€ŒÙ‡Ø§: {str(e)}'
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['GET'])
@permission_classes([IsAuthenticated, IsSuperUser])
def download_log_file(request, file_name):
    """
    Ø¯Ø§Ù†Ù„ÙˆØ¯ Ú©Ø§Ù…Ù„ ÛŒÚ© ÙØ§ÛŒÙ„ Ù„Ø§Ú¯
    ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ø³ÙˆÙ¾Ø± ÛŒÙˆØ²Ø±Ù‡Ø§
    """
    try:
        log_dir = getattr(settings, 'LOG_DIR', os.path.join(settings.BASE_DIR, 'logs'))
        file_path = os.path.join(log_dir, file_name)
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ: ÙÙ‚Ø· ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ .log
        if not file_name.endswith('.log'):
            return Response({
                'success': False,
                'message': 'ÙÙ‚Ø· ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù„Ø§Ú¯ Ù…Ø¬Ø§Ø² Ù‡Ø³ØªÙ†Ø¯'
            }, status=status.HTTP_400_BAD_REQUEST)
        
        if not os.path.exists(file_path):
            return Response({
                'success': False,
                'message': 'ÙØ§ÛŒÙ„ Ù„Ø§Ú¯ ÛŒØ§ÙØª Ù†Ø´Ø¯'
            }, status=status.HTTP_404_NOT_FOUND)
        
        # Ù„Ø§Ú¯ Ú©Ø±Ø¯Ù† Ø¯Ø§Ù†Ù„ÙˆØ¯
        logger.audit_trail(
            f"Superuser '{request.user.username}' downloaded log file '{file_name}'",
            request
        )
        
        # Ø§Ø±Ø³Ø§Ù„ ÙØ§ÛŒÙ„
        with open(file_path, 'rb') as f:
            response = HttpResponse(f.read(), content_type='text/plain; charset=utf-8')
            response['Content-Disposition'] = f'attachment; filename="{file_name}"'
            return response
            
    except Exception as e:
        log_error(f"Failed to download log file: {str(e)}", request)
        return Response({
            'success': False,
            'message': 'Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ Ù„Ø§Ú¯'
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['DELETE'])
@permission_classes([IsAuthenticated, IsSuperUser])
def clear_log_file(request, file_name):
    """
    Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ù…Ø­ØªÙˆØ§ÛŒ ÛŒÚ© ÙØ§ÛŒÙ„ Ù„Ø§Ú¯
    ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ø³ÙˆÙ¾Ø± ÛŒÙˆØ²Ø±Ù‡Ø§
    """
    try:
        log_dir = getattr(settings, 'LOG_DIR', os.path.join(settings.BASE_DIR, 'logs'))
        file_path = os.path.join(log_dir, file_name)
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ
        if not file_name.endswith('.log'):
            return Response({
                'success': False,
                'message': 'ÙÙ‚Ø· ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù„Ø§Ú¯ Ù…Ø¬Ø§Ø² Ù‡Ø³ØªÙ†Ø¯'
            }, status=status.HTTP_400_BAD_REQUEST)
        
        if not os.path.exists(file_path):
            return Response({
                'success': False,
                'message': 'ÙØ§ÛŒÙ„ Ù„Ø§Ú¯ ÛŒØ§ÙØª Ù†Ø´Ø¯'
            }, status=status.HTTP_404_NOT_FOUND)
        
        # Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„ (Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ Ø®Ø§Ù„ÛŒ Ø¬Ø¯ÛŒØ¯)
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(f"# Log file cleared by {request.user.username} at {datetime.now()}\n")
        
        # Ù„Ø§Ú¯ Ú©Ø±Ø¯Ù† Ø¹Ù…Ù„ÛŒØ§Øª
        logger.audit_trail(
            f"Superuser '{request.user.username}' cleared log file '{file_name}'",
            request
        )
        
        return Response({
            'success': True,
            'message': f'ÙØ§ÛŒÙ„ "{file_name}" Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ù¾Ø§Ú© Ø´Ø¯'
        })
        
    except Exception as e:
        log_error(f"Failed to clear log file: {str(e)}", request)
        return Response({
            'success': False,
            'message': 'Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„ Ù„Ø§Ú¯'
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['GET'])
@permission_classes([IsAuthenticated, IsSuperUser])
def get_log_statistics(request):
    """
    Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø± Ùˆ ØªØ­Ù„ÛŒÙ„ Ù„Ø§Ú¯â€ŒÙ‡Ø§
    ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ø³ÙˆÙ¾Ø± ÛŒÙˆØ²Ø±Ù‡Ø§
    """
    try:
        log_dir = getattr(settings, 'LOG_DIR', os.path.join(settings.BASE_DIR, 'logs'))
        
        statistics = {
            'total_files': 0,
            'total_size': 0,
            'files': [],
            'recent_errors': [],
            'top_users': {},
            'activity_by_hour': {}
        }
        
        # Ø¨Ø±Ø±Ø³ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù„Ø§Ú¯
        for file_name in os.listdir(log_dir):
            if file_name.endswith('.log'):
                file_path = os.path.join(log_dir, file_name)
                stat = os.stat(file_path)
                
                statistics['total_files'] += 1
                statistics['total_size'] += stat.st_size
                
                statistics['files'].append({
                    'name': file_name,
                    'size': stat.st_size,
                    'size_human': _human_readable_size(stat.st_size),
                    'modified': datetime.fromtimestamp(stat.st_mtime)
                })
        
        # ØªØ­Ù„ÛŒÙ„ ÙØ§ÛŒÙ„ application.log Ø¨Ø±Ø§ÛŒ Ø¢Ù…Ø§Ø±
        app_log_path = os.path.join(log_dir, 'application.log')
        if os.path.exists(app_log_path):
            errors_today = []
            user_activities = {}
            hourly_activity = {str(h).zfill(2): 0 for h in range(24)}
            
            with open(app_log_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                    
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø·Ù„Ø§Ø¹Ø§Øª
                    entry = _parse_log_line(line)
                    
                    # Ø´Ù…Ø§Ø±Ø´ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ø§Ù…Ø±ÙˆØ²
                    if entry.get('level') in ['ERROR', 'CRITICAL']:
                        if 'today' in entry.get('timestamp', ''):
                            errors_today.append(entry)
                    
                    # Ø¢Ù…Ø§Ø± Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
                    user = entry.get('user', 'anonymous')
                    user_activities[user] = user_activities.get(user, 0) + 1
                    
                    # ÙØ¹Ø§Ù„ÛŒØª Ø³Ø§Ø¹ØªÛŒ
                    timestamp = entry.get('timestamp')
                    if timestamp:
                        try:
                            hour = timestamp.split()[1].split(':')[0]
                            hourly_activity[hour] = hourly_activity.get(hour, 0) + 1
                        except:
                            pass
            
            statistics['recent_errors'] = errors_today[-10:]  # Û±Û° Ø®Ø·Ø§ÛŒ Ø¢Ø®Ø±
            statistics['top_users'] = dict(sorted(
                user_activities.items(), 
                key=lambda x: x[1], 
                reverse=True
            )[:10])
            statistics['activity_by_hour'] = hourly_activity
        
        # Ù„Ø§Ú¯ Ú©Ø±Ø¯Ù† Ø¯Ø³ØªØ±Ø³ÛŒ
        logger.audit_trail(
            f"Superuser '{request.user.username}' viewed log statistics",
            request
        )
        
        return Response({
            'success': True,
            'statistics': statistics,
            'total_size_human': _human_readable_size(statistics['total_size'])
        })
        
    except Exception as e:
        log_error(f"Failed to get log statistics: {str(e)}", request)
        return Response({
            'success': False,
            'message': 'Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø± Ù„Ø§Ú¯â€ŒÙ‡Ø§'
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@api_view(['GET'])
@permission_classes([IsAuthenticated])
def get_my_activity_logs(request):
    """
    Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ù…Ø¹Ù…ÙˆÙ„ÛŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù†Ø¯ Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„ÛŒØª Ø®ÙˆØ¯Ø´Ø§Ù† Ø±Ø§ Ø¨Ø¨ÛŒÙ†Ù†Ø¯
    """
    try:
        page = int(request.GET.get('page', 1))
        per_page = min(int(request.GET.get('per_page', 50)), 200)
        
        log_dir = getattr(settings, 'LOG_DIR', os.path.join(settings.BASE_DIR, 'logs'))
        app_log_path = os.path.join(log_dir, 'application.log')
        
        if not os.path.exists(app_log_path):
            return Response({
                'success': False,
                'message': 'ÙØ§ÛŒÙ„ Ù„Ø§Ú¯ ÛŒØ§ÙØª Ù†Ø´Ø¯'
            }, status=status.HTTP_404_NOT_FOUND)
        
        # ÙÛŒÙ„ØªØ± Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø± Ø¬Ø§Ø±ÛŒ
        user_logs = []
        username = request.user.username
        
        with open(app_log_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if username in line:
                    user_logs.append({
                        'raw': line,
                        'highlight': _highlight_log_line(line)
                    })
        
        # Ù…Ø±ØªØ¨ Ø³Ø§Ø²ÛŒ Ù…Ø¹Ú©ÙˆØ³ (Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† Ø§ÙˆÙ„)
        user_logs.reverse()
        
        # ØµÙØ­Ù‡â€ŒØ¨Ù†Ø¯ÛŒ
        paginator = Paginator(user_logs, per_page)
        try:
            page_obj = paginator.page(page)
        except:
            page_obj = paginator.page(1)
        
        return Response({
            'success': True,
            'username': username,
            'logs': [log['highlight'] for log in page_obj.object_list],
            'pagination': {
                'page': page,
                'per_page': per_page,
                'total_pages': paginator.num_pages,
                'total_count': paginator.count,
                'has_next': page_obj.has_next(),
                'has_previous': page_obj.has_previous(),
            }
        })
        
    except Exception as e:
        log_error(f"Failed to get user activity logs: {str(e)}", request)
        return Response({
            'success': False,
            'message': 'Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù„Ø§Ú¯â€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„ÛŒØª'
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ› ï¸ Helper Functions
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _parse_log_line(line):
    """Ù¾Ø§Ø±Ø³ Ú©Ø±Ø¯Ù† ÛŒÚ© Ø®Ø· Ù„Ø§Ú¯ Ø¨Ù‡ Ø§Ø¬Ø²Ø§ÛŒ ØªØ´Ú©ÛŒÙ„ Ø¯Ù‡Ù†Ø¯Ù‡"""
    try:
        # ÙØ±Ù…Øª: ğŸ“… 2024-01-01 12:00:00 | ğŸ“Š INFO | ğŸ‘¤ admin | ğŸŒ 127.0.0.1 | ğŸ“ module:42 | ğŸ“ message
        pattern = r'ğŸ“… (.+?) \| ğŸ“Š (.+?) \| ğŸ‘¤ (.+?) \| ğŸŒ (.+?) \| ğŸ“ (.+?) \| ğŸ“ (.+)'
        match = re.match(pattern, line)
        
        if match:
            return {
                'timestamp': match.group(1),
                'level': match.group(2),
                'user': match.group(3),
                'ip': match.group(4),
                'location': match.group(5),
                'message': match.group(6)
            }
        
        # ÙØ±Ù…Øª Ù‚Ø¯ÛŒÙ…ÛŒâ€ŒØªØ±
        patterns = [
            r'\[(.+?)\] \[(.+?)\] \[(.+?)\] \[(.+?):(\d+)\] \[User:(.+?)\] \[IP:(.+?)\] - (.+)',
            r'\[(.+?)\] \[(.+?)\] \[(.+?)\] - (.+)'
        ]
        
        for pattern in patterns:
            match = re.match(pattern, line)
            if match:
                if len(match.groups()) == 8:
                    return {
                        'timestamp': match.group(1),
                        'level': match.group(2),
                        'logger': match.group(3),
                        'module': match.group(4),
                        'line': match.group(5),
                        'user': match.group(6),
                        'ip': match.group(7),
                        'message': match.group(8)
                    }
                elif len(match.groups()) == 4:
                    return {
                        'timestamp': match.group(1),
                        'level': match.group(2),
                        'logger': match.group(3),
                        'message': match.group(4)
                    }
    except:
        pass
    
    # Ø§Ú¯Ø± Ù†ØªÙˆØ§Ù†Ø³ØªÛŒÙ… Ù¾Ø§Ø±Ø³ Ú©Ù†ÛŒÙ…
    return {'raw': line}


def _highlight_log_line(line):
    """Ù‡Ø§ÛŒÙ„Ø§ÛŒØª Ú©Ø±Ø¯Ù† Ø®Ø· Ù„Ø§Ú¯ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¨Ù‡ØªØ±"""
    # Ø±Ù†Ú¯â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ø·Ø­
    colors = {
        'DEBUG': '#6c757d',    # Ø®Ø§Ú©Ø³ØªØ±ÛŒ
        'INFO': '#0d6efd',     # Ø¢Ø¨ÛŒ
        'WARNING': '#ffc107',  # Ø²Ø±Ø¯
        'ERROR': '#dc3545',    # Ù‚Ø±Ù…Ø²
        'CRITICAL': '#6f42c1'  # Ø¨Ù†ÙØ´
    }
    
    # ØªØ´Ø®ÛŒØµ Ø³Ø·Ø­
    level = None
    for lvl in colors:
        if lvl in line:
            level = lvl
            break
    
    # Ø§Ú¯Ø± Ø³Ø·Ø­ Ù¾ÛŒØ¯Ø§ Ø´Ø¯ØŒ Ø±Ù†Ú¯â€ŒØ¨Ù†Ø¯ÛŒ Ú©Ù†
    if level and level in colors:
        colored_level = f'<span style="color: {colors[level]}; font-weight: bold;">{level}</span>'
        line = line.replace(level, colored_level)
    
    # Ù‡Ø§ÛŒÙ„Ø§ÛŒØª Ú©Ø§Ø±Ø¨Ø±
    if 'ğŸ‘¤' in line:
        line = line.replace('ğŸ‘¤', '<span style="color: #20c997;">ğŸ‘¤</span>')
    
    # Ù‡Ø§ÛŒÙ„Ø§ÛŒØª IP
    if 'ğŸŒ' in line:
        line = line.replace('ğŸŒ', '<span style="color: #fd7e14;">ğŸŒ</span>')
    
    return line


def _human_readable_size(size_bytes):
    """ØªØ¨Ø¯ÛŒÙ„ Ø¨Ø§ÛŒØª Ø¨Ù‡ ÙØ±Ù…Øª Ø®ÙˆØ§Ù†Ø§"""
    if size_bytes == 0:
        return "0B"
    
    units = ['B', 'KB', 'MB', 'GB', 'TB']
    i = 0
    while size_bytes >= 1024 and i < len(units) - 1:
        size_bytes /= 1024.0
        i += 1
    
    return f"{size_bytes:.2f} {units[i]}"